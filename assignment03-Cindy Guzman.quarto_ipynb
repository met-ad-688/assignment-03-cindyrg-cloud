{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Assignment 03\n",
        "author:\n",
        "  - name: Cindy Guzman\n",
        "    affiliations:\n",
        "      - id: bu\n",
        "        name: Boston University\n",
        "        city: Boston\n",
        "        state: MA\n",
        "number-sections: true\n",
        "date: '2024-11-21'\n",
        "format:\n",
        "   html:\n",
        "    theme: cerulean\n",
        "    toc: true\n",
        "    toc-depth: 2\n",
        "   docx: default\n",
        "   pdf: default\n",
        "execute:\n",
        "  freeze: true\n",
        "date-modified: today\n",
        "date-format: long\n",
        "---\n",
        "\n",
        "# Load the Dataset\n",
        "The instruction below provides you with general keywords for columns used in the lightcast file. See the data schema generated after the load dataset code above to use proper column name. For each visualization, **customize colors, fonts, and styles** to avoid a **2.5-point deduction**. Also, **provide a two-sentence explanation** describing key insights drawn from the graph.\n",
        "\n",
        "1. **Load the Raw Dataset**:\n",
        "   -Use Pyspark to the 'lightcast_data.csv' file into DataFrame:\n",
        "   -You can reuse the previous code.\n",
        "   -[Copying code from your friend constitutes plagiarism. DO NOT DO THIS]{.bloodred-bold}."
      ],
      "id": "d356fc2a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "#| echo: true\n",
        "#| fig-align: center\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from pyspark.sql.functions import col, split, explode, regexp_replace, transform, when\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import col, monotonically_increasing_id\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "pio.renderers.default = \"notebook\"\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n",
        "\n",
        "# Load Data\n",
        "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiline\", \"true\").option(\"escape\", \"\\\"\").csv(\"./data/lightcast_job_postings.csv\")\n",
        "\n",
        "# Show Schema and Sample Data\n",
        "# print(\"---This is Diagnostic check, No need to print it in the final doc---\")\n",
        "\n",
        "# df.printSchema() # comment this line when rendering submission\n",
        "# df.show(5)  "
      ],
      "id": "cdcf76ff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Histogram of SALARY distribution\n",
        "fig = px.histogram(df.toPandas(), x=\"SALARY\", nbins=50, title=\"Salary Distribution\")\n",
        "fig.update_layout(bargap=0.1)"
      ],
      "id": "f4644d7c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preparation"
      ],
      "id": "869e5d01"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Step 1: Casting salary and experience columns\n",
        "df = df.withColumn(\"SALARY\", col(\"SALARY\").cast(\"float\")) \\\n",
        "       .withColumn(\"SALARY_FROM\", col(\"SALARY_FROM\").cast(\"float\")) \\\n",
        "       .withColumn(\"SALARY_TO\", col(\"SALARY_TO\").cast(\"float\")) \\\n",
        "         .withColumn(\"MIN_YEARS_EXPERIENCE\", col(\"MIN_YEARS_EXPERIENCE\").cast(\"float\")) \\\n",
        "       .withColumn(\"MAX_YEARS_EXPERIENCE\", col(\"MAX_YEARS_EXPERIENCE\").cast(\"float\"))\n",
        "       \n",
        "\n",
        "\n",
        "\n",
        "# Step 2: Computing medians for salary columns\n",
        "def compute_median(sdf, col_name):\n",
        "    q = sdf.approxQuantile(col_name, [0.5], 0.01)\n",
        "    return q[0] if q else None\n",
        "\n",
        "median_from = compute_median(df, \"SALARY_FROM\")\n",
        "median_to = compute_median(df, \"SALARY_TO\")\n",
        "       \n",
        "print(\"Medians:\", median_from, median_to)\n",
        "\n",
        "#Step 3: Imputing missing salaries, but not experience\n",
        "df = df.fillna({\n",
        "  \"SALARY_FROM\": median_from, \n",
        "  \"SALARY_TO\": median_to\n",
        "  })\n",
        "\n",
        "# Step 5: Computing average salary\n",
        "df = df.withColumn(\"Average_Salary\", (col(\"SALARY_FROM\") + col(\"SALARY_TO\")) / \n",
        "2)\n",
        "\n",
        "# Step 6: Selecting required columns\n",
        "export_cols = [\n",
        "  \"EDUCATION_LEVELS_NAME\" ,\n",
        "  \"REMOTE_TYPE_NAME\" ,\n",
        "  \"MAX_YEARS_EXPERIENCE\" ,\n",
        "  \"Average_Salary\" ,\n",
        "  \"LOT_V6_SPECIALIZED_OCCUPATION_NAME\"\n",
        "]\n",
        "df_selected = df.select(*export_cols)\n",
        "\n",
        "# Step 7: Saving to CSV\n",
        "pdf = df_selected.toPandas()\n",
        "pdf.to_csv(\"./data/lightcast_cleaned.csv\", index=False)\n",
        "\n",
        "print(\"Data cleaning complete. Rows retained:\", len(pdf))"
      ],
      "id": "659faee4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Salary Distribution by Industry and Employment Type\n",
        "- Compare salary variations across industries.\n",
        "-  **Filter the dataset**\n",
        "  - Remove records where **salary is missing or zero**.\n",
        "- **Aggregate Data**\n",
        "  - Group by **NAICS industry codes**\n",
        "  - Group by **employment type** and compute salary distribution.\n",
        "  - Calculate **salary percentiles** (25th, 50th, 75th) for each group.\n",
        "- **Visualize results**\n",
        "  - Create a **box plot** where:\n",
        "   - **X-axis** = `NAICS2_NAME`\n",
        "   - **Y-axis** = `SALARY_FROM`, or `SALARY_TO`, or `SALARY`\n",
        "   - Group by `EMPLOYMENT_TYPE_NAME`.\n",
        "- Customize colors, fonts, and styles.\n",
        "- **Explanation:** Write two sentences about what the graph reveals.\n",
        "\n",
        "\n",
        "# Salary Analysis by ONET Occupation Type (Bubble Chart)\n",
        "- Analyze how salaries differ across ONET occupation types.\n",
        "-  **Aggregate Data** \n",
        " - Compute **median salary** for each occupation in the **ONET taxonomy**.\n",
        "- **Visualize results**\n",
        "  - Create a **bubble chart** where:\n",
        "   - **X-axis** = `ONET_NAME`\n",
        "   - **Y-axis** = `"
      ],
      "id": "7978bcc8"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/usr/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}