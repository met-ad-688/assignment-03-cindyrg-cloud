{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "58630cfe-fe25-40dd-a729-2a1440477c1e",
      "metadata": {},
      "source": [
        "# Assignment 03\n",
        "\n",
        "Cindy Guzman (Boston University)  \n",
        "November 21, 2024\n",
        "\n",
        "# 1. Load the Dataset\n",
        "\n",
        "The instruction below provides you with general keywords for columns\n",
        "used in the lightcast file. See the data schema generated after the load\n",
        "dataset code above to use proper column name. For each visualization,\n",
        "**customize colors, fonts, and styles** to avoid a **2.5-point\n",
        "deduction**. Also, **provide a two-sentence explanation** describing key\n",
        "insights drawn from the graph.\n",
        "\n",
        "1.  **Load the Raw Dataset**: -Use Pyspark to the ‘lightcast_data.csv’\n",
        "    file into DataFrame: -You can reuse the previous code.\n",
        "    -<span class=\"bloodred-bold\">Copying code from your friend\n",
        "    constitutes plagiarism. DO NOT DO THIS</span>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1423bd4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Lightcast Job Postings Analysis\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df = spark.read.option(\"header\", \"true\") \\\n",
        "               .option(\"inferSchema\", \"true\") \\\n",
        "               .option(\"multiLine\", \"true\") \\\n",
        "               .option(\"escape\", \"\\\"\") \\\n",
        "               .csv(\"/home/ubuntu/assignment-03-cindyrg-cloud/data/lightcast_job_postings.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54c9ef85",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from pyspark.sql.functions import col, split, explode, regexp_replace, transform, when\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import col, monotonically_increasing_id\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "pio.renderers.default = \"notebook\"\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n",
        "\n",
        "# Load Data\n",
        "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiline\", \"true\").option(\"escape\", \"\\\"\").csv(\"./data/lightcast_job_postings.csv\")\n",
        "\n",
        "# Show Schema and Sample Data\n",
        "# print(\"---This is Diagnostic check, No need to print it in the final doc---\")\n",
        "\n",
        "# df.printSchema() # comment this line when rendering submission\n",
        "# df.show(5)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f83a76c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Histogram of SALARY distribution\n",
        "from pyspark.sql.functions import floor\n",
        "\n",
        "binned_df = df.filter(col(\"SALARY\").isNotNull() & (col(\"SALARY\") > 0)) \\\n",
        "              .withColumn(\"SALARY_BIN\", floor(col(\"SALARY\") / 5000) * 5000) \\\n",
        "              .groupBy(\"SALARY_BIN\").count() \\\n",
        "              .orderBy(\"SALARY_BIN\") \\\n",
        "              .toPandas()\n",
        "\n",
        "fig = px.bar(binned_df, x=\"SALARY_BIN\", y=\"count\", title=\"Salary Distribution by Bin\")\n",
        "fig.update_layout(xaxis_title=\"Salary Bin\", yaxis_title=\"Frequency\", bargap=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71dbaab3-bccf-474f-ad16-3da83a59cb00",
      "metadata": {},
      "source": [
        "# 2. Step 1: Create Companies Table (Primary Key: company_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c84051a",
      "metadata": {},
      "outputs": [],
      "source": [
        "companies_df = df.select(\n",
        "  col(\"company\"),\n",
        "  col(\"company_name\"),\n",
        "  col(\"company_raw\"),\n",
        "  col(\"company_is_staffing\")\n",
        ").distinct().withColumn(\"company_id\", monotonically_increasing_id())\n",
        "# companies_df.show(5)\n",
        "companies = companies_df.toPandas()\n",
        "companies.drop(columns=[\"company\"], inplace=True)\n",
        "companies.rename(columns={\"company_is_staffing\": \"is_staffing\"}, inplace=True)\n",
        "companies.to_csv(\"./output/companies.csv\", index=False)\n",
        "companies.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcb916f4-6bea-48d0-9f28-d27797c9f690",
      "metadata": {},
      "source": [
        "# 3. Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "477c9bf1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Casting salary and experience columns\n",
        "df = df.withColumn(\"SALARY\", col(\"SALARY\").cast(\"float\")) \\\n",
        "       .withColumn(\"SALARY_FROM\", col(\"SALARY_FROM\").cast(\"float\")) \\\n",
        "       .withColumn(\"SALARY_TO\", col(\"SALARY_TO\").cast(\"float\")) \\\n",
        "       .withColumn(\"MIN_YEARS_EXPERIENCE\", col(\"MIN_YEARS_EXPERIENCE\").cast(\"float\")) \\\n",
        "       .withColumn(\"MAX_YEARS_EXPERIENCE\", col(\"MAX_YEARS_EXPERIENCE\").cast(\"float\")) \n",
        "\n",
        "       \n",
        "# Step 2: Computing medians for salary columns\n",
        "def compute_median(sdf, col_name):\n",
        "    q = sdf.approxQuantile(col_name, [0.5], 0.01)\n",
        "    return q[0] if q else None\n",
        "\n",
        "median_from = compute_median(df, \"SALARY_FROM\")\n",
        "median_to = compute_median(df, \"SALARY_TO\")\n",
        "median_salary = compute_median(df, \"SALARY\")\n",
        "       \n",
        "print(\"Medians:\", median_from, median_to, median_salary)\n",
        "\n",
        "#Step 3: Imputing missing salaries, but not experience\n",
        "df = df.fillna({\n",
        "  \"SALARY_FROM\": median_from, \n",
        "  \"SALARY_TO\": median_to,\n",
        "  \"SALARY\": median_salary\n",
        "  })\n",
        "\n",
        "# Step 5: Computing average salary\n",
        "df = df.withColumn(\"Average_Salary\", (col(\"SALARY_FROM\") + col(\"SALARY_TO\")) / 2)\n",
        "\n",
        "# Step 6: Selecting required columns\n",
        "export_cols = [\n",
        "  \"EDUCATION_LEVELS_NAME\",\n",
        "  \"REMOTE_TYPE_NAME\",\n",
        "  \"MAX_YEARS_EXPERIENCE\",\n",
        "  \"Average_Salary\",\n",
        "  \"SALARY\", \n",
        "  \"LOT_V6_SPECIALIZED_OCCUPATION_NAME\"\n",
        "]\n",
        "df_selected = df.select(*export_cols)\n",
        "\n",
        "# Step 7: Saving to CSV\n",
        "pdf = df_selected.toPandas()\n",
        "pdf.to_csv(\"./data/lightcast_cleaned.csv\", index=False)\n",
        "\n",
        "print(\"Data cleaning complete. Rows retained:\", len(pdf))\n",
        "pdf.head() # Preview the first few rows"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "134a9783-291a-498f-983c-ef172e0ca267",
      "metadata": {},
      "source": [
        "# 4. Your code for 1st question here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e84c678a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Filter out missing or zero salary values\n",
        "pdf = df.filter(df[\"SALARY\"] > 0).select(\"EMPLOYMENT_TYPE_NAME\", \"SALARY\").toPandas()\n",
        "pdf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb005af3-26b1-4b3d-a231-11f75836c8ac",
      "metadata": {},
      "source": [
        "# 5. Clean employment type names for better readability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae02c04d",
      "metadata": {},
      "outputs": [],
      "source": [
        "pdf[\"EMPLOYMENT_TYPE_NAME\"] = pdf[\"EMPLOYMENT_TYPE_NAME\"].apply(lambda x: re.sub(r\"[^\\x00-\\x7F]+\",\"\", x))\n",
        "pdf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bba396f6-34b6-4f48-90fb-8fbeb31d8966",
      "metadata": {},
      "source": [
        "# 6. Compute median salary for sorting\n",
        "\n",
        "median_salaries =\n",
        "pdf.groupby(“EMPLOYMENT_TYPE_NAME”)\\[“SALARY”\\].median()\n",
        "\n",
        "# 7. Sort employment types based on median salary in descending order\n",
        "\n",
        "sorted_employment_types =\n",
        "median_salaries.sort_values(ascending=False).index\n",
        "\n",
        "# 8. Apply sorted categories\n",
        "\n",
        "pdf\\[“EMPLOYMENT_TYPE_NAME”\\] = pd.Categorical()\n",
        "\n",
        "# 9. Salary Distribution by Industry and Employment Type\n",
        "\n",
        "-   Compare salary variations across industries.\n",
        "-   **Filter the dataset**\n",
        "-   Remove records where **salary is missing or zero**.\n",
        "-   **Aggregate Data**\n",
        "    -   Group by **NAICS industry codes**\n",
        "    -   Group by **employment type** and compute salary distribution.\n",
        "    -   Calculate **salary percentiles** (25th, 50th, 75th) for each\n",
        "        group.\n",
        "-   **Visualize results**\n",
        "    -   Create a **box plot** where:\n",
        "    -   **X-axis** = `NAICS2_NAME`\n",
        "    -   **Y-axis** = `SALARY_FROM`, or `SALARY_TO`, or `SALARY`\n",
        "    -   Group by `EMPLOYMENT_TYPE_NAME`.\n",
        "-   Customize colors, fonts, and styles.\n",
        "-   **Explanation:** Write two sentences about what the graph reveals.\n",
        "\n",
        "# 10. Salary Analysis by ONET Occupation Type (Bubble Chart)\n",
        "\n",
        "-   Analyze how salaries differ across ONET occupation types.\n",
        "-   **Aggregate Data**\n",
        "-   Compute **median salary** for each occupation in the **ONET\n",
        "    taxonomy**.\n",
        "-   **Visualize results**\n",
        "    -   Create a **bubble chart** where:\n",
        "    -   **X-axis** = `ONET_NAME`\n",
        "    -   **Y-axis** = `Median Salary`\n",
        "    -   **Size** = Number of job postings\n",
        "    -   Apply custom colors and font styles.\n",
        "-   **Explanation:** Write two sentences about what the graph reveals.\n",
        "\n",
        "# 11. Salary by Education Level\n",
        "\n",
        "-   Create two groups:\n",
        "    -   **Bachelor’s or lower** (Bachelor’s, GED, Associate, No\n",
        "        Education Listed)\n",
        "    -   **Master’s or PhD** (Master’s degree, Ph.D. or professional\n",
        "        degree)\n",
        "-   Plot scatter plots for each group using, `MAX_YEARS_EXPERIENCE`\n",
        "    (with jitter), `Average_Salary`,\n",
        "    `LOT_V6_SPECIALIZED_OCCUPATION_NAME`\n",
        "-   Then, plot histograms overlaid with KDE curves for each group.\n",
        "-   This would generate two scatter plots and two histograms.\n",
        "-   **After each graph, add a short explanation** of key insights.\n",
        "\n",
        "# 12. Salary by Remote Work Type\n",
        "\n",
        "-   Split into three groups based on `REMOTE_TYPE_NAME`:\n",
        "    -   Remote  \n",
        "    -   Hybrid  \n",
        "    -   Onsite (includes `[None]` and blank)\n",
        "-   Plot scatter plots for each group using, `MAX_YEARS_EXPERIENCE`\n",
        "    (with jitter), `Average_Salary`,\n",
        "    `LOT_V6_SPECIALIZED_OCCUPATION_NAME`\n",
        "-   Also, create salary histograms for all three groups.\n",
        "-   **After each graph, briefly describe any patterns or comparisons.**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3",
      "path": "/usr/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
